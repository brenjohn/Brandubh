The zero bot uses a method to select moves which integrates a neural network with a type of tree search very similar to Monte Carlo tree search. A key feature that the neural network most have is two output heads. One head should contain just a single neuron with a hyperbolic tan activation function to ensure its' output is between -1 and 1. This head should be trained to predict the expected reward/winner (1 for zero bot to win and -1 for the opponent to win) of a given board position. The other head should be similar to a policy head (in that it was the same number of neurons and a softmax activation) but it will be used differently. This head, instead of being used to predict moves, will be used to predict how often branches of the search tree, stemming from a given board position, will be explored by the monte carlo like tree search alogorithm.

When the zero bot is given a board position to select a next move for, it starts builing a tree data structure whose root represents the given board position and the children of a node represent the board position created when a particular move is made from the parent board position. The node class used by the bot to build the tree consists of the following attributes:

TreeNode:
* A Brandubh game_state, representing the current board position.
* A real number called 'value'. This is the initial Q-value produced by the neural network when the associated board position is passed to it.
* An integer 'total_visit_count' keeping track of the number of times this node was visited during the tree search.
* A dictionary of branch objects (described below) keyed by tuples representing potential moves to be made with the save game_state.
* References to a parent node and the move made to get from the parent node to the current node, if they exist, and references to all child nodes stemming from the current node.

When a node is added to the tree, a branch object is created for every possible child node, stemming from the node, that might be created. The role of these branch objects is to keep track of statistics associated with visits from the tree search algorithm to the corresponding child node. Namely, it keeps track of the total number of visits to the correponding child node and the total Q-value of moves that stem from the child node and explored by the tree search. The total Q-value divided by the total visit count can be taken as a measure of the expected reward to be gained from the board position represented by the child node. The attributes of the branch object are:

Branch:
* A real number called prior. When a node is created for a board position, the board position is fed into the neural network to get the Q-value and a probability distribution over possible moves is also produced by the policy-like head predicting where the tree search will explore from there. These probabilities are called priors and the prior for a particular branch/child node is saved here.
* total_visit_count
* total_value

Summary of move selection/tree search algorithm:
1) Given a board position to select a move for, the board position os first fed into the neural network to get a Q-value for the board position and a list of prior probabilies. The Q-value is used to create a TreeNode to represent the board position and the priors are used to create a Branch object for all possible board positions that could follow. This TreeNode is the root of the search tree and the branchs are saved in a dictionary contained in the TreeNode.

2) The root node is set as the current node.

3) A branch stemming from the current node is selected using the below method and the current node is switched to the node associated with the selected branch. This is repeated until a leaf node becomes the current node and the current selected branch has no associated TreeNode yet.

*) Branch selection: The branch selected is the one that maximises the following expression: Q + c*p*sqrt(N)/(1+n), where Q = expected reward of board position (branch.total_value/branch.visit_count), c is a hyperparameter, p is the prior of the branch, n is branch.visit_count and N is the total number of visits to the to the parent/current node (node.total_visit_count).

4) if the board position of the current node doesn't have a winner, a TreeNode is created for the next selected move/branch by first applying the move to a copy of the current board position and then feeding the result into the neural network to get the associated Q-value and priors. The new node has its total_visit_count incremented and the all of the nodes the algorithm visited to get to the current node also have their total_visit_count incremented. The branch objects associated with these nodes have their visit_counts incremented and their value incremented with the new Q-value of the new node (multiplied by -1 for opponent moves).

5) Otherwise, if the board position does have a winner and the game is over in the current board position, no new node is created and all of the visited nodes/branches have their visit counts incremented and values incremented with 1 or -1 depeneding on the winner of the game.

6) return to step 2 unless maximum number of iterations reached.

7) The move selected by the bot is the move corresponding to the branch stemming from the root node with the most number of visits. (Note, if all branches have a large number of visits then this is equivalent to choosing the one with the largest expected reward as this is the one that gets selected most often by the branch selection algorithm. If a branch only has a few visits, the estimate for the expected reward may not be reliable)

 

